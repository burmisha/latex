Итак для нахождения значений $\mb a$ и $R$ необходимо решить следующую задачу:
\begin{equation}
\label{min:main}
			\begcas{
			&R^2 + C\suml_i\xi_i \to \min\limits_{\mb a, R,\mb\xi}, \\
			&\norm{\mb x_i-\mb a}^2\le R^2 + \xi_i,\quad\xi_i\ge0,\quad i = 1,\ldots,N.
			} 
\end{equation}
Функция Лагранжа этой задачи имеет вид
\begin{multline*}
	\Ell(\mb a, R,\mb\xi,\mb\alpha,\mb\gamma)=
		R^2 + C\suml_i\xi_i - \suml_i\gamma_i\xi_i  -\\
	-\suml_i\alpha_i\cbr{R^2 + \xi_i - \cbr{\mb x_i\cdot\mb x_i - 2\mb a\cdot\mb x_i + \mb a\cdot\mb a}},
\end{multline*}
где $\alpha_i\ge 0$  и $\gamma_i\ge 0$ --- множители Лагранжа.
Необходимым условием минимума является равенство нулю частных производных функции Лагранжа по всем переменным:
\begin{equation}
	\label{minLag}
	\begin{array}{ll}
		\dd \Ell R = 0: & \suml_i \alpha_i = 1 \:\cbr{\text{случай $R = 0$ рассмотрим отдельно,}}\\
		\dd \Ell{\mb a} = 0: & \mb a = \cfrac{\suml_i\alpha_i\mb x_i}{\suml_i \alpha_i}= \suml_i \alpha_i\mb x_i,\\
		\dd \Ell{\xi_i} = 0: & \gamma_i = C - \alpha_i, \;\; i = 1,\ldots,N.
	\end{array}
\end{equation}

Из последнего уравнения получаем, что $\alpha_i = C - \gamma_i$. 
Таким образом, мы получаем новые ограничения на $\alpha_i$: 
$$0\le\alpha_i\le C, \;\; i = 1,\ldots,N.$$

Если это ограничение выполнено, то мы можем вычислить $\gamma_i$ по формуле $\gamma_i = C - \alpha_i$, и при этом автоматически будет выполнено условие $\gamma_i\ge 0$.

Тогда для функции Лагранжа получим выражение
{
\newcommand\ai[0]{\alpha_i\,}
\newcommand\aj[0]{\alpha_j\,}
\newcommand\mbx[1]{\mb x_#1}
\newcommand\cd[0]{\!\cdot\!}
\al{
\Ell(\mb a, R,&\mb\xi,\mb\alpha,\mb\gamma)
	= 	R^2 - \suml_i\ai R^2 + C\suml_i\xi_i - \suml_i\ai\xi_i  +\\
	&+ \suml_i\ai\mbx i\cd\mbx i -  2\suml_i\ai\mb a\cd\mbx i + \suml_i\ai\mb a\cd\mb a - \suml_i\gamma_i\xi_i =\\
	&= R\cd R\cd\cbr{1-\suml_i\ai} +\suml_i\xi_i\cbr{C-\ai-\gamma_i} + \\
	&+ 	\suml_i\ai\mbx i\cd\mbx i - 2 \suml_i\ai\suml_j\aj\mbx j\cd\mbx i
	+ 	\suml_{i,j}\ai\aj \mbx j\cd \mbx i = \\
	&= 	\suml_i\ai\mbx i\cd\mbx i-\suml_{i,j}\ai\aj\mbx j\cd\mbx i \to \max_{\mb\alpha}.
}
}

Полученное выражение является квадратичной формой. 
Тогда его максимум находится по известным алгоритмам решения задач квадратичного программирования. 
По оптимальным значениям $\mb{\alpha}$ мы сможем найти оптимальное значение центра гиперсферы $\mb a$ и отступов $\mb{\xi}$ используя соотношения (\ref{minLag}). 
Те векторы $\mb x_i$, для которых $\alpha_i=0$ и $\gamma_i=C$, лежат внутри гиперсферы, те , для которых $0<\alpha_i<C$ и $0<\gamma_i<C$~--- на её границе, а те, для которых $\alpha_i=C$ и $\gamma_i=0$, лежат вне гиперсферы и имеют ненулевой отступ $\mb\xi$. 
Радиус $R$ определяется как расстояние от центра гиперсферы $\mb a$ до опорных векторов лежащих на границе гиперсферы.

Если же $R = 0$, то задача (\ref{min:main}) имеет вид 
\begin{equation}
			\begcas{
			&C\suml_i\xi_i \to \min\limits_{\mb a, \mb\xi}, \\
			&\norm{\mb x_i-\mb a}^2\le \xi_i,\quad\xi_i\ge0,\quad i = 1,\ldots,N.
			} 
\end{equation}
т.е.
\begin{equation}
			C\suml_i\norm{\mb x_i-\mb a}^2 \to \min\limits_{\mb a},
\end{equation} 
а эта задача соответствует методу наименьших квадратов. Тогда $\mb a = \frac{\sum_i \mb x_i}N$. 
При этом следует понимать, что значение $R=0$ обнуляет обобщающую способность нашего классификатора, поэтому следует отказываться от такого решения, если есть выбор. 
Здесь же стоит отметить, что $R = 0$ обязательно, если $C < \frac1N,$ где $N$~--- число объектов в обучающей выборке, поскольку в этом случае условия на $\mb \alpha$ несовместны.

Для возможности описания данных более гибкой формой, нежели сфера, в работе \cite{Tax2001} предлагается использовать потенциальные функции \cite{Izerman1979}. Наиболее часто используемыми потенциальными функциями являются полиномиальная
$$K_p(\mb x_i, \mb x_j) = \cbr{1 + \mb x_i \cdot \mb x_j}^p$$
и радиальная базисная функция Гаусса
$$K(\mb x_i, \mb x_j) = \exp\cbr{-\frac{\norm{\mb x_i - \mb x_j}^2}{2s^2}}.$$
Таким образом, чтобы получить улучшенную модель описания данных, необходимо заменить в функции Лагранжа операцию вычисления
скалярного произведения двух векторов вычислением значения потенциальной функции двух аргументов.
