Для оценки качества работы алгоритма предлагается ввести метрику. 
Следуя работе  \cite{Romanenko2012}, будем измерять качество одноклассовой класификации в терминах точности и полноты. 
В нашем случае точность (precision)~--- доля верно классифицированных объектов тестовой выборки среди всех объектов, отнесенных алгоритмом к единственному классу. 
Полнота (recall)~--- доля верно классифицированных объектов тестовой выборки среди всех объектов, принадлежащих к единственному классу. 
Более высокие значения точности и полноты соответствуют лучшему качеству классификации. 
В качестве агрегированного показателя, объединяющего точность $P$ и полноту $R$ используем $F_1$-меру \cite{Rijsbergen1979}:
$$F_1 = \frac{2PR}{P+R}.$$

Для проведения вычислительного эксперимента сгенерируем $N=400$ случайных точек $\fbr{\mb x_i}_{i=1}^N$ из распределения (\ref{PhiXARC}) при размерности пространства $2$ (для наглядности), положив направления смещений случайными и придав параметрам значения $a = \cbr{1,2}\T, R = 3, c = 0{,}2.$
После этого проведем $t{\times}q$-fold кросс-валидацию с $t = 10, q = 3$, скользящим контролем подбирая параметр $C$ и вычисляя $F_1$-метрику при каждом его значении. При этом всё, что лежит вне сферы мы считаем не принадлежащим классу, а всё, что внутри,~--- считаем.
В результате получим следующую зависимость значения метрики от $C$ (см. рисунок \ref{eps:CrValLong}).
Из графика видно, что при $C\to 0$ обобщающая способность также стремится к нулю, поскольку практически отсутствует штраф за непопадание в класс при обучении. 
При этом большие штрафы заставляют необоснованно увеличивать сферу, снижая точность.

Пример работы алгоритма приведен на рисунке \ref{eps:example} при параметре $C = 0{,}007.$ 
Зеленым изображена граница истинного распределения, красным~--- построенного.
Видно, что здесь $C$ слишком мало и сфера получилось слишком маленькой.

\addeps{CrValLong}{Модельные данные. Зависимость $F_1$-метрики от параметра регуляризации $C$.}  % CV_0.000-0.010-0.200_T10_Q3.eps
\addeps{example}{Пример результата работы алгоритма при $C = 0{,}007.$}


Для проведения эксперимента на реальных данных были выбраны доступные в открытом доступе уже вычисленные признаки сообщений \footnote{UCI Machine Learning Repository \href{http://archive.ics.uci.edu/ml/datasets/Spambase}{http://archive.ics.uci.edu/ml/datasets/Spambase}}. 
Здесь для обучения бралась небольшая часть спам-документов (200 из ~1800). 
Сперва они линейно отображались в куб $[0, 1]^k$ ($k = 57$~--- размерность пространства), а затем по ним строилась сфера в этом 57-мерном пространстве. 
Для контроля все остальные данные преобразовывались по тому же правилу (что не гарантирует их попадание в этот же куб), после чего проверялось попадание в построенную сферу и вычислялась $F_1$-метрика. 
Здесь в контроле уже участвуют объекты как объекты из исследуемого класса (спам-сообщений), так и не из него, хотя обучение происходило только на объектах целевого класса. 
Результаты подбора параметра $C$ изображены на рисунке (\ref{eps:CVReal}). Данные усреднены по 20 случайным выборкам по 200 объектов из 1800.

\addeps{CVReal}{Реальные данные. Зависимость $F_1$-метрики от параметра регуляризации $C$}
% Real_N200_0.0300-0.0050-0.1500_T20.eps


В обоих экспериментах отчетливо прослеживаются максимумы метрики, что свидетельствует о наличии в обеих задачах оптимального значения параметра $C.$
