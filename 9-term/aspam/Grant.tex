\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{graphics,graphicx,epsfig}
\usepackage{color}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsthm,mathtext,cite,enumerate,float}
\usepackage[sumlimits, intlimits]{amsmath}
\usepackage{enumitem} \setlist{nolistsep}
\usepackage{textcase} 

\textheight=24cm		\textwidth=16cm
\oddsidemargin=0mm 		\evensidemargin=0mm
\topmargin=-2,5cm
\parindent=24pt 		\parskip=3pt 
\footnotesep=3ex
\raggedbottom %\flushbottom
\clubpenalty=10000		\widowpenalty=10000 	\tolerance=500
\renewcommand{\baselinestretch}{1.25}

\input macro.tex

\newcommand\nameofpart[1]{\noindent\maintext{#1}\par}
\begin{document}
	\nameofpart{Фундаментальная научная проблема, на анализ и обобщение результатов по которой, направлен проект}
	Объектом исследования данного проекта является выявление закономерностей и взаимосвязей в реально существующих объектах или событиях между совокупностью их явных (наблюдаемых) характеристик-признаков, с одной стороны, и свойств, скрытых от непосредственного наблюдения, с другой. 
	В данном проекте изучается возможность определения принадлежности объектов некоторому множеству. 
	В таком случае возможно говорить о задаче, как о задаче обучения распознавания образов или задаче классификации, при этом найденная зависимость называется решающим правилом. 
	Традиционно различают обучение с учителем (по прецедентам) и без учителя. 
	В данной работе используется метод обучения с учителем, при котором существует конечное число объектов, для которых известны и наблюдаемые, и скрытые характеристики (т.\,е. принадлежность классу). 
	Множество таких объектов будем называть обучающей выборкой.

	Методы обучению распознаванию образов развиваются очень быстро, однако одновременно с этим процессом интенсивно растет область желаемого применения этих алгоритмов. 
	При этом происходит наложение 4 процессов:
	\begin{itemize}
		\item рост требований к результату в уже существующих областях,
		\item увеличение размеров и усложнение обучающих выборок с ростом самих областей применения,
		\item применение в областях, где ранее подобный подход не применялся,
		\item появление совершенно новых областей, где вовсе нет классических подходов.
	\end{itemize}
	При этом необходимо как можно точнее понимать, в каких областях какие подходы применимы, а также какие требования необходимы для корректного использования методов.

	Хорошим и практически важным примером задачи распознавания образов является классификация электронных писем и сообщений на предмет наличия в них спама. 
	При попытке решения этой задачи возникают 4 существенных затруднения. 
	Во-первых, постоянный рост использования электронных писем и всё более высокое проникновение в жизнь людей непрерывно увеличивают как количество изучаемых объектов, так и их разнородность.
	Во-вторых, технологии рассылки спама непрерывно совершенствуются с целью обхода уже существующих фильтров, что также увеличивает количество разнородных объектов.
	В-третьих, существенные, но тяжело формализуемые, отличия спам-писем, от полезных. 
	При этом шаблонность письма вовсе не означает его вредоносность, поскольку это может быть рассылкой от одного из используемых сервисов.
	В-четвертых, возникающие трудности в составлении обучающей выборки. Для традиционных алгоритмов обучения с учителем является очень важной достаточная широта представленных в обучающей выборке объектов, однако в данном случае классы существенно неравноправны, по следующим причинам:
	\begin{itemize}
	 	\item полное отсутствие характеристик, присущих всем полезным письмам, и их очень высокая разнородность,
	 	\item спам-письма не скрываются людьми, тогда как полезные охраняются законом и менее доступны,
	 	\item как следствие, доступные обучающие выборки содержат достаточное количество спам-писем, однако слишком бедны для сколь-либо полного описания полезных писем.
	\end{itemize}

	Аналогичными свойствами обладают задачи диагностики заболеваний, поиска отклонений в работе технических устройств, т.\,е. в задачах с существенно неравноправными классами.
	С связи с такими ограничениями разумно полностью отказаться от попытки описать и построить границу между двумя классами, а описать лишь один класс, используя в обучающей выборке объекты только этого класса, а второй же класс определить как всё, что не попало в описанный.

	Таки образом возникает \MakeTextUppercase{фундаментальная научная проблема разработки алгоритмов и методов обучения распознаванию образов в задачах с одним классом.}

	При этом необходимо понимать, что построение и применение таких алгоритмов должно быть достаточно быстрым, тогда как количество признаков изучаемых объектов очень велико, как и число самих объектов. 
	Кроме того определение некоторых характеристик объекта доступно, однако требует значительных материальных или временных затрат. 
	Поэтому необходимо среди всех доступных признаков объектов выделить необходимое минимальное число, позволяющее решить задачу с требуемой точностью. Такой подход позволит обрабатывать большие объемы поступающих данных в разумные сроки.
	Отсюда вытекает \MakeTextUppercase{вторая фундаментальная научная проблема, на решение которой направлен данный проект: модификация существующих методов распознавания образов таким образом, что число необходимых признаков для работы алгоритма минимально.}

	Решение обозначенных выше фундаментальных проблем предполагает решение следующих трех задач:
	\begin{enumerate}
		\item[1.] Математическая постановка задачи обучения по прецедентам в конечномерном пространстве признаков с присутствием в обучающей выборке объектов лишь одного класса.
		\item[2.] Модификация математической постановки задачи, которая позволит эффективно отбирать признаки.
		\item[3.] Проверка работы построенных алгоритмов на искусственных (модельных) и реальных данных.
	\end{enumerate}
	Далее мы будем придерживаться именно этой нумерации задач.

	\nameofpart{Актуальность и современное состояние исследований по данной научной проблеме} 

	\newcommand\task[1]{{\textsf{Задача #1.}}}

	В течение всего своего развития человечество интенсивно накапливало данные о различных явлениях, а с широким распространением электронной техники количество получаемой информации стало расти гораздо быстрее. 
	В связи с этим при попытке решения современных задач возникает следующая проблема: данные есть в большом количестве, однако, с одной стороны, нет никакой информации относительно представительности, полноты и полезности для решения, а с другой стороны, что еще сильнее усложняет ситуацию, нет практически реализуемого способа получить такую информацию.

	\task1 Ныне существующие подходы к решению задач одноклассовой классификации основаны на эвристических предположениях о том, какие модели следует рассматривать. 
	Основным алгоритмом является SVDD, предлагающий описывать изучаемый класс объектов сферой как можно меньшего размера. 
	Также разработаны модификации этого алгоритма, позволяющие расширить класс областей, описывающих объекты. 
	Такие подходы работают на практике, однако обладают принципиальными недостатками:
	\begin{itemize}
		\item Невозможность определить область применимости. 
		Зачастую, зная на практике источник данных и их физическую интерпретацию, можно заранее определить, какие статистические подходы заведомо неприменимы к задаче. 
		Простая эвристическая постановка же не накладывает условий на модель данных и может быть необоснованно применена к неподходящим данным. 
		В таком случае может быть получен положительный результат, однако нет возможности определить, можно ли улучшить модель и получить алгоритм с большей обобщающей способностью.
		\item Отсутствие четкой связи с модификациями модели. Эвристическая постановка задачи допускает лишь эвристические модификации, влияние которых на качество построенной модели невозможно строго определить.
	\end{itemize}
	Таким образом, по причине использования в существующей литературе лишь эвристической постановки задачи, актуальна проблема вероятностной постановки задачи, более гибкой и не обладающей указанными недостатками.

	\task2 При работе со сколь-либо большими объемами данных всегда возникает вопрос, а все ли используемые данные действительно необходимы. 
	Дело в том, что наличие лишних данных может заставить алгоритм работать неустойчиво, снижая качество. 
	Также зачастую получение, хранение и обработка больших объемов данных требует значительных материальных, временных и человеческих ресурсов. 
	По этим причинам требуется проводить отсев бесполезных признаков. 

	Ныне существует большое число подходов к решению этой задачи, многие из которых имеют одновременно и эвристическую, и вероятностную постановку. Главное преимущество эвристической постановки --- возможность получения некоторого решения, которое, однако, не способно претендовать на оптимальность. 
	В свою очередь, строгая вероятностная постановка может оказаться сложнее, однако будет более гибкой, а также будет обладать возможностью комбинации с построенной вероятностной постановкой задачи (1).

	\task3 Ныне проблема спам-сообщений является очень актуальной и к её решению прилагаются значительные усилия крупнейших интернет-компаний. 
	По данным <<Лаборатории Касперского>>, доля спама в почтовом трафике в ноябре 2012 года составила в среднем 62,9\%. %http://www.securelist.com/ru/analysis/208050780/Spam_v_noyabre_2012
	Одновременно с развитием технологий фильтрации спама, развиваются и технологии маскировки спама под полезные письма. 
	Поэтому применение новых алгоритмов в этой области может оказаться полезным и дать выигрыш в этой <<гонке вооружений>>.

	\nameofpart{Конкретная фундаментальная задача в рамках указанной проблемы}
	Построение одноклассовых классификаторов, обладающих вероятностной подоплекой предполагает решение следующих конкретных фундаментальных проблем.

	\task1 Математическая вероятностная постановка задачи обучению одноклассовой классификации по прецедентам в конечномерном пространстве действительных признаков.

	\task2 Разработка алгоритмов обучения на основе вероятностной постановки.

	\task3 Разработка методов отбора признаков на основе вероятностной модели объектов.

	Таким образом, \MakeTextUppercase{указанная проблема может рассматриваться как задача обучения распознаванию объектов некоторого класса.} 
	При этом существует потребность в точном определении границ применимости используемой модели, что может быть достигнуто использованием вероятностных моделей. 
	Поэтому \MakeTextUppercase{первая фундаментальная задача: создание вероятностного подхода к задаче одноклассовой классификации}.

	При этом само по себе построение вероятностной модели данных не дает никаких оснований полагать, что удастся существующие данные достаточно хорошо ею описать в силу возможной чрезмерной сложности самой модели. 
	Отсюда вытекает \MakeTextUppercase{вторая фундаментальная задача: исследование классов вероятностных моделей одноклассовой классификации, при которых возможно эффективное построение классификаторов.} %  Это про кернелы

	В то же время, даже будучи эффективно обученной модель может оказаться слишком тонко настроенной на прецеденты, что сокращает её обобщающую способность, т.\,е. происходит переобучение. 
	Ясно, что в таком случае следует применить отбор признаков и регуляризовать модель. 
	Существует большое число методов регуляризации построения алгоритмов классификации, однако нашей целью является построение вероятностной модели данных, поэтому возникает 
	\MakeTextUppercase{третья фундаментальная задача: построение вероятностного подхода к задаче отбора признаков в одноклассовой классификации.}
	
	\nameofpart{Предлагаемые методы и подходы}
	\nameofpart{Ожидаемые научные результаты, которые планируется получить по завершению проекта}

\end{document} 