В работе рассматривается задача восстановления регрессии по обучающей совокупности, одна из основных задач машинного обучения \cite{vap99}. 
Под обучающей совокупностью здесь и далее понимается некоторое подмножество объектов реального мира, заданных своим признаковым описанием, вместе с известными значениями своих скрытых характеристик. 
В работе рассматривается случай числовых признаков и числовой скрытой характеристики.
В качестве регрессионной модели предлагается использовать класс линейных параметрических моделей \cite{ivch09}. 
Для обеспечения устойчивости задачи по поиску оптимальной совокупности параметров модели вводится регуляризация, которая вносит в модель дополнительные внешние параметры, называемые структурными.
Примерами таких методов регуляризации являются гребневая регрессия (ridge regression, \cite{hoerl70}), лассо (LASSO, \cite{tib96}), метод опорных векторов в задачах регрессии (SVM Regression, \cite{dru96}), Elastic Net \cite{zou05}.

При этом оптимальные значения структурных параметров неизвестны и требуют отдельного подбора. 
Одним из методов подбора структурных параметров является скользящий контроль (кросс-валидация, cross-validation, CV, \cite{voron}) .
Существуют различные модификации этого подхода: полный CV, CV по случайным разбиениям, контроль по отложенным данным, контроль по отдельным объектам (leave-one-out CV), контроль по $q$ блокам ($q$-fold CV), контроль по $r\times q$ блокам ($r\times q$-fold CV). 
Эти методы обладают естественной интерпретацией, однако зачастую крайне вычислительно неэффективны в своём применении, требуя многократного построения алгоритма обучения, тем самым затрудняя подбор оптимальных структурных параметров. 
По этой причине в работах \cite{cawley,che14} были предложены методы, позволяющие при некоторых ограничениях и допущениях на свойства обучающей совокупности получить более эффективные процедуры скользящего контроля.
В работе \cite{gre12} была предложена идея дифференциального скользящего контроля, при котором объекты не целиком исключаются из обучающей совокупности на этапе обучения, 
а изучается влияние изменения их веса на обобщающую способность алгоритма при фиксированных значениях структурных параметров. 
При этом такой подход также оказывается вычислительно эффективным, но и более того допускает естественное обобщение на более широкий класс задач, чем рассмотренный в работе.

В данной работе показано, как принцип дифференциальной кросс-валидации может быть к методу регуляризации Elastic Net, 
проведено сравнение с другими беспереборными подходами оценки структурных параметров, а также экспериментально изучены различные способы подбора оптимальных параметров.
