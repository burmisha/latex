\begin{abstract}
При решении задач восстановления регрессии по обучающей совокупности, заданной признаковым описанием, одним из базовых подходов является поиск решения в пространстве линейных функций. 
Для поиска оптимального решения применяется регуляризация с помощью Elastic Net, требующая введения дополнительных структурных параметров. 
Классическим способом подбора этих параметров является скользящий контроль с поочерёдным исключением объектов из обучающей выборки.
Такой подход обладает высокой вычислительной сложностью из-за необходимости проводить обучение столько раз, сколько объектов содержится в обучающем множестве.
В работе предложено использование дифференциального скользящего контроля, не требующего полного перебора всех объектов при обучении. 
При такой методике вместо полного исключения объекта из обучающей выборки лишь уменьшается его вес и изучается изменение регрессионных остатков, что позволяет построить критерий дифференциального скользящего контроля.
Проведены вычислительные эксперименты, показывающие эффективность применения этой методики.
\end{abstract}